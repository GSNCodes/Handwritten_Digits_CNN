{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hand_Written_Digits_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4It2ZVR90eo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D, Flatten, MaxPooling2D, Dropout,Activation,MaxPool2D\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEUFsnWA-ws1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_Train,Y_Train),(X_Test,Y_Test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88BHbcJmDJvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Train = (X_Train/255.0) \n",
        "X_Test  = (X_Test/255.0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6_vmt_0_BkN",
        "colab_type": "code",
        "outputId": "85446e9f-88c7-4778-eff4-aac81faca2a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X_Train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MubpAYo1_J8g",
        "colab_type": "code",
        "outputId": "79578315-744d-4802-a893-30ec5d8d7e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "X_Test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxmPIvzJ_Pfm",
        "colab_type": "code",
        "outputId": "6f5bbf8d-df48-47e9-d3d8-159a2df16c15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_Train[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.16470588, 0.4627451 , 0.85882353, 0.65098039,\n",
              "        0.4627451 , 0.4627451 , 0.02352941, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.40392157, 0.94901961, 0.99607843, 0.99607843, 0.99607843,\n",
              "        0.99607843, 0.99607843, 0.25882353, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.07058824, 0.90980392, 0.99607843, 0.99607843, 0.99607843,\n",
              "        0.99607843, 0.99607843, 0.93333333, 0.2745098 , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.40784314, 0.95686275, 0.99607843, 0.87843137,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.55294118, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.81176471, 0.99607843, 0.82352941,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.13333333, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.32941176, 0.80784314, 0.99607843,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.16078431, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.09411765, 0.81960784,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.67058824, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.35686275, 0.5372549 , 0.99215686,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.43921569, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.15686275, 0.83921569, 0.98039216, 0.99607843, 0.99607843,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.13333333, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.31764706, 0.96862745, 0.99607843, 0.99607843, 0.99607843,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.57254902, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.43137255, 0.96470588, 0.99607843, 0.99607843,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.67058824, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.28627451, 0.34901961, 0.34901961,\n",
              "        0.36470588, 0.94117647, 0.99607843, 0.67058824, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.00392157, 0.50196078, 0.99607843, 0.85882353, 0.12156863,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.02745098, 0.99607843, 0.99607843, 0.83921569, 0.10980392,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.54117647, 0.99607843, 0.99607843, 0.45490196, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.0745098 , 0.69411765, 0.35294118, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.09803922,\n",
              "        0.94117647, 0.99607843, 0.99607843, 0.13333333, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.64313725, 0.99607843, 0.84313725, 0.24705882,\n",
              "        0.14117647, 0.        , 0.2       , 0.34901961, 0.80784314,\n",
              "        0.99607843, 0.99607843, 0.54509804, 0.03137255, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.22352941, 0.77254902, 0.99607843, 0.99607843,\n",
              "        0.87058824, 0.70588235, 0.94509804, 0.99607843, 0.99607843,\n",
              "        0.99215686, 0.83529412, 0.04313725, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.54901961, 0.41176471, 0.99607843,\n",
              "        0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "        0.9254902 , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.02745098, 0.45882353,\n",
              "        0.45882353, 0.64705882, 0.99607843, 0.99607843, 0.9372549 ,\n",
              "        0.19607843, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGts6fKU_s7v",
        "colab_type": "code",
        "outputId": "c6e99378-5b35-4da0-f6db-25471d5245eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "Y_Train[10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stdw0ZMT_u4D",
        "colab_type": "code",
        "outputId": "498d573b-b223-4ac2-d252-29a81ba477bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.imshow(X_Train[10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f37a1cc9d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4OvznHX_zF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_Train = X_Train.reshape(60000,28,28,1)\n",
        "X_Test  = X_Test.reshape(10000,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSS9ozfoApIF",
        "colab_type": "code",
        "outputId": "979c5f84-2def-46c8-9356-6950a41bcfc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#1-Hot Encoding\n",
        "\n",
        "y_train_oneh = to_categorical(Y_Train)\n",
        "y_test_oneh  = to_categorical(Y_Test)\n",
        "\n",
        "print(y_train_oneh[10]) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksWFx0XZ35lF",
        "colab_type": "code",
        "outputId": "b31163fa-0608-4cb6-cae9-4eff29870c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        }
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(10,kernel_size=5,activation='relu',padding='same',input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(8,kernel_size=5,activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(10,kernel_size=5,activation='relu',padding='same',input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(8,kernel_size=5,activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10,activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 10)        260       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 8)         2008      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 10)        2010      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 12, 12, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 8, 8)           2008      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4, 4, 8)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 7,766\n",
            "Trainable params: 7,726\n",
            "Non-trainable params: 40\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQI4yYrL4tmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLrxTztd4y0T",
        "colab_type": "code",
        "outputId": "e5616751-41b7-4eac-c7a4-f3c17424e4ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_Train,y_train_oneh, validation_data=(X_Test,y_test_oneh),epochs=50,batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 1.1193 - accuracy: 0.6139 - val_loss: 0.1969 - val_accuracy: 0.9526\n",
            "Epoch 2/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.4598 - accuracy: 0.8425 - val_loss: 0.1072 - val_accuracy: 0.9778\n",
            "Epoch 3/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3598 - accuracy: 0.8827 - val_loss: 0.0839 - val_accuracy: 0.9792\n",
            "Epoch 4/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.3061 - accuracy: 0.9042 - val_loss: 0.0679 - val_accuracy: 0.9833\n",
            "Epoch 5/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2457 - accuracy: 0.9277 - val_loss: 0.0578 - val_accuracy: 0.9848\n",
            "Epoch 6/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2287 - accuracy: 0.9347 - val_loss: 0.0472 - val_accuracy: 0.9871\n",
            "Epoch 7/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.2136 - accuracy: 0.9394 - val_loss: 0.0403 - val_accuracy: 0.9892\n",
            "Epoch 8/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1965 - accuracy: 0.9447 - val_loss: 0.0457 - val_accuracy: 0.9880\n",
            "Epoch 9/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1906 - accuracy: 0.9456 - val_loss: 0.0497 - val_accuracy: 0.9875\n",
            "Epoch 10/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1850 - accuracy: 0.9480 - val_loss: 0.0358 - val_accuracy: 0.9901\n",
            "Epoch 11/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1787 - accuracy: 0.9505 - val_loss: 0.0377 - val_accuracy: 0.9911\n",
            "Epoch 12/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1741 - accuracy: 0.9516 - val_loss: 0.0392 - val_accuracy: 0.9908\n",
            "Epoch 13/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1764 - accuracy: 0.9499 - val_loss: 0.0360 - val_accuracy: 0.9911\n",
            "Epoch 14/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1701 - accuracy: 0.9514 - val_loss: 0.0338 - val_accuracy: 0.9907\n",
            "Epoch 15/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1634 - accuracy: 0.9537 - val_loss: 0.0362 - val_accuracy: 0.9914\n",
            "Epoch 16/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1654 - accuracy: 0.9530 - val_loss: 0.0439 - val_accuracy: 0.9893\n",
            "Epoch 17/50\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1607 - accuracy: 0.9547 - val_loss: 0.0403 - val_accuracy: 0.9898\n",
            "Epoch 18/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1606 - accuracy: 0.9539 - val_loss: 0.0350 - val_accuracy: 0.9910\n",
            "Epoch 19/50\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1563 - accuracy: 0.9556 - val_loss: 0.0389 - val_accuracy: 0.9909\n",
            "Epoch 20/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1524 - accuracy: 0.9571 - val_loss: 0.0381 - val_accuracy: 0.9900\n",
            "Epoch 21/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1535 - accuracy: 0.9575 - val_loss: 0.0393 - val_accuracy: 0.9901\n",
            "Epoch 22/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1540 - accuracy: 0.9572 - val_loss: 0.0309 - val_accuracy: 0.9935\n",
            "Epoch 23/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1513 - accuracy: 0.9575 - val_loss: 0.0319 - val_accuracy: 0.9917\n",
            "Epoch 24/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1482 - accuracy: 0.9577 - val_loss: 0.0313 - val_accuracy: 0.9923\n",
            "Epoch 25/50\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1477 - accuracy: 0.9584 - val_loss: 0.0374 - val_accuracy: 0.9922\n",
            "Epoch 26/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1487 - accuracy: 0.9585 - val_loss: 0.0328 - val_accuracy: 0.9914\n",
            "Epoch 27/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1455 - accuracy: 0.9592 - val_loss: 0.0323 - val_accuracy: 0.9908\n",
            "Epoch 28/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1438 - accuracy: 0.9595 - val_loss: 0.0339 - val_accuracy: 0.9917\n",
            "Epoch 29/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1453 - accuracy: 0.9599 - val_loss: 0.0392 - val_accuracy: 0.9906\n",
            "Epoch 30/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1465 - accuracy: 0.9589 - val_loss: 0.0363 - val_accuracy: 0.9909\n",
            "Epoch 31/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1406 - accuracy: 0.9608 - val_loss: 0.0348 - val_accuracy: 0.9924\n",
            "Epoch 32/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1424 - accuracy: 0.9602 - val_loss: 0.0373 - val_accuracy: 0.9904\n",
            "Epoch 33/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1395 - accuracy: 0.9622 - val_loss: 0.0300 - val_accuracy: 0.9927\n",
            "Epoch 34/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1353 - accuracy: 0.9633 - val_loss: 0.0323 - val_accuracy: 0.9924\n",
            "Epoch 35/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1382 - accuracy: 0.9625 - val_loss: 0.0418 - val_accuracy: 0.9909\n",
            "Epoch 36/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1348 - accuracy: 0.9637 - val_loss: 0.0356 - val_accuracy: 0.9915\n",
            "Epoch 37/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1353 - accuracy: 0.9634 - val_loss: 0.0403 - val_accuracy: 0.9909\n",
            "Epoch 38/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1339 - accuracy: 0.9630 - val_loss: 0.0422 - val_accuracy: 0.9909\n",
            "Epoch 39/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1339 - accuracy: 0.9634 - val_loss: 0.0333 - val_accuracy: 0.9924\n",
            "Epoch 40/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1312 - accuracy: 0.9652 - val_loss: 0.0368 - val_accuracy: 0.9916\n",
            "Epoch 41/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1328 - accuracy: 0.9643 - val_loss: 0.0350 - val_accuracy: 0.9915\n",
            "Epoch 42/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1287 - accuracy: 0.9654 - val_loss: 0.0337 - val_accuracy: 0.9920\n",
            "Epoch 43/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1279 - accuracy: 0.9660 - val_loss: 0.0382 - val_accuracy: 0.9914\n",
            "Epoch 44/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1248 - accuracy: 0.9669 - val_loss: 0.0382 - val_accuracy: 0.9915\n",
            "Epoch 45/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1217 - accuracy: 0.9671 - val_loss: 0.0358 - val_accuracy: 0.9917\n",
            "Epoch 46/50\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1207 - accuracy: 0.9671 - val_loss: 0.0350 - val_accuracy: 0.9927\n",
            "Epoch 47/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1235 - accuracy: 0.9663 - val_loss: 0.0347 - val_accuracy: 0.9917\n",
            "Epoch 48/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1214 - accuracy: 0.9667 - val_loss: 0.0423 - val_accuracy: 0.9911\n",
            "Epoch 49/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1197 - accuracy: 0.9681 - val_loss: 0.0377 - val_accuracy: 0.9922\n",
            "Epoch 50/50\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1207 - accuracy: 0.9682 - val_loss: 0.0294 - val_accuracy: 0.9936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDOCM2SSDh4p",
        "colab_type": "text"
      },
      "source": [
        "**Achieved an accuracy of around ~99.4%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWQEDurBEGXZ",
        "colab_type": "code",
        "outputId": "f23297f4-4c0a-48c0-9aaa-c420072b3ce2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Comparing with some data from the training set\n",
        "\n",
        "predictions = model.predict(X_Test[100:110])\n",
        "print(np.argmax(predictions,axis=1))\n",
        "\n",
        "print(Y_Test[100:110])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 0 5 4 9 9 2 1 9 4]\n",
            "[6 0 5 4 9 9 2 1 9 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KoEBhadIRPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,10):\n",
        "  image = np.array(X_Test[i],dtype='float')\n",
        "  image_reshaped = image.reshape((28,28))\n",
        "  plt.imshow(image_reshaped,cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Fjur5FNNGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}